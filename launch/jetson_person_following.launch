<?xml version="1.0"?>
<launch>
  <arg name="camera_name" value="/csi_cam_0/qhd"/>

  <include file="$(find monocular_people_tracking)/launch/jetson_csi_camera.launch"/>
  <include file="$(find monocular_people_tracking)/launch/tf_openpose.launch">
    <arg name="image_topic" value="$(find camera_name)/image_rect"/>
    <arg name="model" value="mobilenet_thing"/>
    <arg name="resolution" value="368x368"/>
  </launch>

  <node pkg="monocular_people_tracking" type="monocular_people_tracking_node" name="monocular_people_tracking">
    <remap from="camera_info" to="$(arg camera_name)/camera_info"/>

    <!-- detection parameters -->
    <param name="detection_confidence_thresh" value="0.1"/>
    <param name="detection_border_thresh_w" value="100"/>
    <param name="detection_border_thresh_h" value="25"/>

    <!-- UKF parameters -->
    <param name="measurement_noise_pix_cov" value="100"/>
    <param name="process_noise_pos_cov" value="0.03"/>
    <param name="process_noise_vel_cov" value="0.01"/>
    <param name="process_noise_height_cov" value="1e-10"/>

    <!-- tracking parameters -->
    <param name="association_maha_sq_thresh" value="9.0"/>
    <param name="association_neck_ankle_max_dist" value="200"/>
    <param name="association_neck_max_dist" value="150"/>
    <param name="tracking_remove_trace_thresh" value="5"/>
    <param name="tracking_newtrack_dist2exists_thersh" value="100"/>
  </node>

  <node pkg="monocular_person_following" type="monocular_person_following_node" name="monocular_person_following_node" output="screen">
    <remap from="image" to="$(arg camera_name)/image_rect"/>
    <!--
    /// @brief
    /// Initial state:
    ///   if there is a person in front of the camera (within imprinting_max_dist),
    ///   the person is registered as the target
    /// Initial Training state:
    ///   the target person features are added to the classifier a certain time (initial_training_num_samples),
    ///   then, the sytem transits to the tracking state
    /// Tracking state:
    ///   if the identification confidence of the target is lower than min_target_confidence,
    ///   the system judges that the target is lost, and transits to ReID state
    /// ReID state:
    ///   if a track shows a confidence higher than reid_confidence_thresh several times (reid_positive_count),
    ///   the track is reidentified as the target, and the system transits to Tracking state
    -->
    <param name="imprinting_max_dist" value="4.0"/>
    <param name="initial_training_num_samples" value="10"/>
    <param name="min_target_confidence" value="-0.1"/>
    <param name="reid_confidence_thresh" value="0.2"/>
    <param name="reid_positive_count" value="5"/>
  </node>

  <node pkg="monocular_person_following" type="visualization.py" name="visualization_node" output="screen">
    <param name="show" value="false"/>
  </node>
</launch>
